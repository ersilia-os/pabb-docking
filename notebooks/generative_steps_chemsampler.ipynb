{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Steps for novel PabB Inhibitors\n",
    "\n",
    "This notebook contains the steps to use the scorer.py funciton plus chemsampler to sample and generate compounds optimised for PabB binding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import os\n",
    "import pandas as pd \n",
    "import csv\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit import Chem\n",
    "from ersilia import ErsiliaModel\n",
    "from chemsampler import ChemSampler\n",
    "\n",
    "# set paths for data, results, and source code\n",
    "DATAPATH = \"../data\"\n",
    "RESULTSPATH = \"../results\"\n",
    "SOURCEPATH = \"../src\"\n",
    "\n",
    "# activate the chemsampler environment (assumed to have been done already)\n",
    "# (no code is included here as the exact method of activating the environment can vary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial dataset preparation\n",
    "\n",
    "The reference_library.csv from https://github.com/ersilia-os/groverfeat/blob/main/data/reference_library.csv was downloaded and addded to the repo. This was filtered based loosely on Lipinski's rule of 5, but with caveats for lead compounds. More info can be found on the wiki page here https://en.wikipedia.org/wiki/Lipinski%27s_rule_of_five.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of producing this dataset of ~200k lead-like compounds is to dock a large number of potential leads into PabB and obtain docking scores. Compounds that dock with a high affinity when compared to the known binders can be used alongside the known binders as a list of compounds to seed chemsampler. We are looking for 50-100 compounds to use as a seed. Chemsampler will then sample and generate ~1 million compounds. These can be filtered, remaining compounds re-docked and further generation can occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths for the input and output files\n",
    "smiles_csv = os.path.join(DATAPATH, 'smiles', 'reference_library.csv')\n",
    "filtered_smiles = os.path.join(DATAPATH, 'smiles', 'testfiltered_std_smiles.csv')\n",
    "\n",
    "# Read the SMILES strings from the CSV file into a DataFrame\n",
    "df = pd.read_csv(smiles_csv, skiprows=1, header=None, names=['SMILES']) #can add skiprows=1 is there is a smiles header\n",
    "\n",
    "# Create an empty list to store the selected SMILES strings\n",
    "selected = []\n",
    "\n",
    "# Loop through the SMILES strings and filter by molecular properties\n",
    "for s in df['SMILES']:\n",
    "    mol = Chem.MolFromSmiles(s)\n",
    "    mw = Descriptors.MolWt(mol)\n",
    "    logp = Descriptors.MolLogP(mol)\n",
    "    hacceptors = Descriptors.NumHAcceptors(mol)\n",
    "    hdonors = Descriptors.NumHDonors(mol)\n",
    "    numrotatablebonds = Descriptors.NumRotatableBonds(mol)\n",
    "    if 250 <= mw <= 450 and 1 <= logp <= 3 and hacceptors <= 5 and hdonors <= 4 and numrotatablebonds <= 5: \n",
    "        selected.append(s)\n",
    "\n",
    "# Write the selected SMILES strings to a new CSV file\n",
    "df_selected = pd.DataFrame({'SMILES': selected})\n",
    "df_selected.to_csv(filtered_smiles, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999381"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"SMILES\"]) #how many original smiles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201515"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected) #how many in our list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = (range(0, 201515))\n",
    "len(id_list) # must create a list of 'IDs' for the ID column - this is required for the scorer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_selected = os.path.join(DATAPATH, \"smiles\", \"200k_for_chemsampler.csv\")\n",
    "\n",
    "dict = {'ID': id_list, 'SMILES': selected}  \n",
    "df = pd.DataFrame(dict) \n",
    "df.to_csv(filtered_selected, index=False) \n",
    "\n",
    "#saves a .csv file with a column for ID and a column for SMILES which will be used to run the first round of docking into PabB."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chemsampler\n",
    "\n",
    "From the docked 200k compounds the top 50 were chosen and seeded to chemsampler. This is to return a long (~1 million?) list of compounds that can be filtered for re-docking.\n",
    "\n",
    "I also ran Chemsampler using the 2 known binders (abyssomicin C and chorismate), as a test run, to ensure the chemsampler-filtering pipeline works correctly.\n",
    "\n",
    "Below is the code for the generation of a list of smiles, along with the code to run each sampler individually, and the code to run all of the samplers together. Alterations in the sampler.py file allow for specific samplers to be chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C1C(=C)C2=C3[C@@]4([C@@H1]([C@@H1](O)[C@@H1](O3)[C@@H1](C4)C)/C=C/C(=O)[C@H1]1CC)OC2=O',\n",
       " 'C=C(O[C@@H1]1C=C(C=C[C@H1]1O)C(=O)O)Br',\n",
       " 'O1[C@@H1]2[C@H1](O)[C@@H1]3[C@]4(OC(=O)C(=C41)C([C@H1](C)C[C@H1](C)C(Br)/C=C/3)=O)C[C@H1]2C',\n",
       " 'C1=C/[C@@H1]2[C@H1]([C@@H1]3[C@H1](C)C[C@]24C(=C(C(=O)O4)C(=O)[C@@H1](C[C@H1](C)C/1=O)C)O3)C',\n",
       " 'C=C(O[C@H1]1[C@H1](O)SC=CC(C(=O)O)=C1)C(=O)O',\n",
       " 'O=C(C(O[C@@H1]1C=C(C(=O)O)C=C[C@H1]1O)=C)I',\n",
       " 'C1CC[C@@H1](C(/C=C/[C@@H1]2[C@@H1](O)[C@H1]3OC4=C(C(=O)O[C@@]42C[C@H1]3C)C1)=O)C',\n",
       " 'OC(=O)C=1C=C[C@@H1](O)[C@@H1](C=1)OC(=C)CS(O)=O',\n",
       " 'C1=C/[C@@H1]2[C@@H1](O)[C@@H1]3[C@H1](C)C[C@@]24OC(CC([O-1])[C@H1](C)C[C@@H1](C/1=O)C)=C4O3',\n",
       " 'CC1C[C@H1](C[C@@H1](C)C(C2=C3[C@]4(C[C@H1]([C@@H1]([C@H1](O)[C@H1]41)O3)C)OC2=O)=O)C',\n",
       " 'O=C(O)C1=CC(OC(C(=O)O)=C(F)F)C(O)C=C1',\n",
       " '[C@@H1]1[C@H1]2OC3=C4C(O[C@]3(C[C@H1]2C)[C@@H1]1/C=C/C(=O)[C@H1](C[C@@H1](C)C4=O)C)=O',\n",
       " 'C=1\\\\C(C)[C@H1]([C@H1](C)C(=O)C=2C(O[C@]34C=2O[C@@H1]([C@H1](C)C3)[C@@H1]([C@H1]4/C=1)O)=O)CC',\n",
       " '[C@H1]12OC=3[C@@]4(OC(=O)C=3C([C@@H1](C[C@@H1](C(=O)/C=C/[C@@H1]41)C)C)=O)C[C@H1]2C',\n",
       " 'O[C@@H1]1[C@@H1]2[C@]34C[C@H1]([C@@H1]1OC3=C(C(O4)=O)C[C@H1](Br)C[C@@H1](C(=O)/C=C/2)C)C',\n",
       " 'C=C(OC1C=C(C(=O)O)C(I)=CC1O)C(=O)O',\n",
       " '[C@@H1]1(OC(C(O)=O)=C)C=C(C=C[C@H1]1O)C(C)OBr',\n",
       " 'C[C@H1]1[C@@H1]2OC=3[C@@]4(C1)[C@@H1]([C@H1]2O)/C=C/C([C@H1](C[C@H1](CC=3C(=O)O4)C)F)=O',\n",
       " 'O=C(C1=C[C@H1]([C@H1](O)C=C1)OC(C(O)=O)=C)C(=O)C',\n",
       " 'C[C@H1]1C[C@H1]C(=O)C=2C(=O)O[C@]34C[C@@H1](C)[C@H1]([C@H1]3/C=C/C1=O)OC=24']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the path to the input CSV file\n",
    "input_csv = os.path.join(DATAPATH, \"..\", \"..\", \"cstest\", \"filtered_output.csv\")\n",
    "\n",
    "# set the column index to use (default is 0)\n",
    "column_index = 0 # this can be changed to 2 if using the outputs of the docking, as it will contain affinity, ID and smiles columns\n",
    "\n",
    "# read the SMILES strings from the CSV file\n",
    "smiles_list = []\n",
    "with open(input_csv, 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    next(csv_reader) # skip the header row\n",
    "    for row in csv_reader:\n",
    "        smiles_list.append(row[column_index])\n",
    "\n",
    "# store the SMILES strings in a variable\n",
    "smiles = smiles_list\n",
    "smiles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for all samplers, and can tweak in sampler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running all samplers now with biomodal, moler, and molib turned off\n",
    "\n",
    "cs = ChemSampler()\n",
    "resultsALL = cs.sample(smiles, num_samples=1000)\n",
    "resultsALL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual samplers are below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = ChemSampler(samplers_list= [\"ChemblSampler\"])\n",
    "resultsCh = cs.sample(smiles, num_samples=1000)\n",
    "resultsCh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = ChemSampler(samplers_list= [\"StonedSampler\"])\n",
    "resultsSt = cs.sample(smiles, num_samples=1000)\n",
    "resultsSt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = ChemSampler(samplers_list= [\"MolerSampler\"])\n",
    "resultsMo = cs.sample(smiles, num_samples=1000)\n",
    "resultsMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = ChemSampler(samplers_list= [\"PubChemSampler\"])\n",
    "resultsPc = cs.sample(smiles, num_samples=1000)\n",
    "resultsPc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = ChemSampler(samplers_list= [\"SmallWorldSampler\"])\n",
    "resultsSW = cs.sample(smiles, num_samples=1000)\n",
    "resultsSW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = ChemSampler(samplers_list= [\"BimodalSampler\"])\n",
    "resultsBM = cs.sample(smiles, num_samples=1000)\n",
    "resultsBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = ChemSampler(samplers_list= [\"FasmifraSampler\"])\n",
    "resultsF = cs.sample(smiles, num_samples=1000)\n",
    "resultsF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = ChemSampler(samplers_list= [\"MollibSampler\"])\n",
    "results = cs.sample(smiles, num_samples=1000)\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering \n",
    "\n",
    "Here, I outline the steps required to filter the output of chemsampler and the docking runs.\n",
    "\n",
    "Filters to be used:\n",
    "- MW 250-450\n",
    "- logP 1-4\n",
    "- number of rotatable bonds <=5\n",
    "- number of H bond acceptors <=5\n",
    "- Number of H bond donors <=5\n",
    "\n",
    "The above can be done simply in code.\n",
    "\n",
    "Extra filters to apply, from Ersilia model hub:\n",
    "- Retrosynthetic accessibility score (cutoff >0.5 - this score is either high or low, Y/N basically)\n",
    "- Aqueous solubilty (cutoff here -4 to 4, although drugs may be in the -2 to 2 territory. Too soluble and it will be cleared, not soluble enough and it will accumulate)\n",
    "- Passive permeability (The optimal log10 permeability coefficient (log Papp) for a drug will depend on the specific application and target of the drug. In general, a good log Papp value for a drug should be between -5 and -8 cm/s. Log Papp values in this range indicate that the drug is sufficiently lipophilic to cross cell membranes efficiently, but not so lipophilic that it is unable to dissolve in the watery environment of the body or that it is prone to accumulation in fatty tissues. However, it is important to note that the optimal log Papp value for a specific drug will depend on a variety of factors, including the drug's target tissue or organ, its desired pharmacokinetic profile, and its intended route of administration. Therefore, it is recommended to assess the log Papp of drugs experimentally in vitro and in vivo to determine the optimal range for a specific drug.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resultsALL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m([x \u001b[39mfor\u001b[39;00m k,v \u001b[39min\u001b[39;00m resultsALL\u001b[39m.\u001b[39mitems() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m v])) \n\u001b[1;32m      2\u001b[0m results_list \n\u001b[1;32m      3\u001b[0m \u001b[39m# this is turning the results in the resultsALL dictionary into a list\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resultsALL' is not defined"
     ]
    }
   ],
   "source": [
    "results_list = list(set([x for k,v in resultsALL.items() for x in v])) \n",
    "results_list \n",
    "# this is turning the results in the resultsALL dictionary into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path for the output file\n",
    "filtered_by_desc_output = os.path.join(DATAPATH, '..', '..', 'cstest', 'filtered_by_desc_output.csv')\n",
    "\n",
    "# Create an empty list to store the filtered SMILES strings\n",
    "filtered = []\n",
    "\n",
    "# Loop through the results_list and filter by molecular properties\n",
    "for s in results_list:\n",
    "    mol = Chem.MolFromSmiles(s)\n",
    "    mw = Descriptors.MolWt(mol)\n",
    "    logp = Descriptors.MolLogP(mol)\n",
    "    hacceptors = Descriptors.NumHAcceptors(mol)\n",
    "    hdonors = Descriptors.NumHDonors(mol)\n",
    "    numrotatablebonds = Descriptors.NumRotatableBonds(mol)\n",
    "    if 250 <= mw <= 450 and 1 <= logp <= 4 and hacceptors <= 5 and hdonors <= 5 and numrotatablebonds <= 5: \n",
    "        filtered.append(s)\n",
    "\n",
    "# Create a dictionary with the filtered SMILES strings\n",
    "dict = {'smiles': filtered}\n",
    "\n",
    "# Convert the dictionary to a pandas DataFrame\n",
    "df = pd.DataFrame(dict)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv(filtered_by_desc_output, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Ersilia models can be run froma a single cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_by_desc_ouptut = os.path.join(DATAPATH, \"..\", \"..\", \"cstest\", \"filtered_by_desc_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyndenrooms/miniconda3/envs/chemsampler/lib/python3.8/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "# Set paths and filenames\n",
    "data_path = os.path.join(DATAPATH, '..', '..', 'cstest') # this is only for this run, as the original DATAPATH will be sufficient when running the code later.\n",
    "filtered_smiles_output = os.path.join(data_path, 'filtered_by_desc_output.csv')\n",
    "all_filters_output = os.path.join(data_path, 'testall_filters_output.csv')\n",
    "\n",
    "# Load Ersilia models\n",
    "ra_model = ErsiliaModel('retrosynthetic-accessibility')\n",
    "sol_model = ErsiliaModel('eos6oli')\n",
    "permeability_model = ErsiliaModel('eos2hbd')\n",
    "\n",
    "# Serve models and run predictions\n",
    "ra_model.serve()\n",
    "input_smiles = pd.read_csv(filtered_smiles_output)['smiles']\n",
    "ra_scores = ra_model.predict(input_smiles, output='pandas')\n",
    "ra_model.close()\n",
    "\n",
    "# Filter by RA score\n",
    "ra_filtered = ra_scores[ra_scores['ra_score'] > 0.5]\n",
    "\n",
    "sol_model.serve()\n",
    "solubility = sol_model.predict(ra_filtered['input'].tolist(), output='pandas')\n",
    "sol_model.close()\n",
    "\n",
    "# Filter by solubility\n",
    "sol_filtered = solubility[(solubility['solubility'] > -3) & (solubility['solubility'] < 3)]\n",
    "\n",
    "permeability_model.serve()\n",
    "permeability = permeability_model.predict(sol_filtered['input'].tolist(), output='pandas')\n",
    "permeability_model.close()\n",
    "\n",
    "# Filter by permeability\n",
    "permeability_filtered = permeability[(permeability['Log10PermCoeff'] > -8) & (permeability['Log10PermCoeff'] < -4)]\n",
    "\n",
    "# Drop unnecessary columns, rename input column, and save output to CSV\n",
    "permeability_filtered.drop(columns=['Log10PermCoeff', 'key'], inplace=True)\n",
    "permeability_filtered = permeability_filtered.rename(columns={'input': 'smiles'})\n",
    "permeability_filtered.to_csv(all_filters_output, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below is what was used on the test database.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now want to run ersilia's models \n",
    "all_filters_output = os.path.join(DATAPATH, \"..\", \"..\", \"cstest\", \"test.csv\")\n",
    "\n",
    "from ersilia import ErsiliaModel\n",
    "mdl = ErsiliaModel(\"retrosynthetic-accessibility\")\n",
    "mdl.serve()\n",
    "input_smiles = filtered_by_desc_ouptut\n",
    "df1 = mdl.predict(input_smiles, output=\"pandas\")\n",
    "mdl.close()\n",
    "\n",
    "df2 = df1[df1[\"ra_score\"] > 0.01] # this is to be changed to >0.5 for the larger datasets\n",
    "\n",
    "mdl = ErsiliaModel(\"eos6oli\")\n",
    "mdl.serve()\n",
    "df3 = mdl.predict(df2[\"input\"].tolist(), output=\"pandas\")\n",
    "mdl.close()\n",
    "df4 = df3[df3[\"solubility\"] > -4]\n",
    "df4 = df4[df4[\"solubility\"] < 4] # this can be tightened to 3 or 2 for the larger datasets, but is not as important\n",
    "\n",
    "mdl = ErsiliaModel(\"eos2hbd\")\n",
    "mdl.serve()\n",
    "df5 = mdl.predict(df4[\"input\"].tolist(), output=\"pandas\")\n",
    "mdl.close()\n",
    "df6 = df5[df5[\"Log10PermCoeff\"] < -4]\n",
    "df6 = df6[df6[\"Log10PermCoeff\"] > -8]\n",
    "\n",
    "df6.drop(columns = [\"Log10PermCoeff\", \"key\"], inplace=True)\n",
    "df6 = df6.rename(columns={'input': 'smiles'})\n",
    "df6.to_csv(all_filters_output, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docking-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
